{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "6rArcV417GhV",
    "outputId": "ebdf613d-43c8-483d-d53a-ee55ac6e25fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount._DEBUG = False\n",
    "drive.mount('/content/gdrive/')\n",
    "#!ls /content/gdrive/'My Drive'/Deeplearning/RA_Work/NEMD_Simulations/all_data/data_dump.pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "S2UbX98A7Zo-",
    "outputId": "5eaef58a-2cae-4c2e-b38e-9ff08d8d2032"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data  one_particle_double_well_10X.HDF5  one_particle_double_well.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls /content/gdrive/'My Drive'/Deeplearning/RA_Work/one_particle_double_well\n",
    "working_dir = '/content/gdrive/My Drive/Deeplearning/RA_Work/one_particle_double_well'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "XHw0ZGUl7FMd",
    "outputId": "28d28e03-cb6d-4f02-efec-c70fffdfc99e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1.15.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lib imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as PathEffects\n",
    "%matplotlib inline\n",
    "plt.style.use('default')\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_palette('muted')\n",
    "sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sys, os, io, string, shutil, math\n",
    "import glob\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import FastICA \n",
    "from sklearn import preprocessing\n",
    "from IPython.display import display\n",
    "import scipy.linalg as la\n",
    "import re\n",
    "from tabulate import tabulate\n",
    "from scipy import stats\n",
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "import random\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "a-sXwUhLAOeP",
    "outputId": "e9574430-22bc-4c02-9fc5-616954093ce2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160\n",
      "(160, 9999, 6)\n",
      "100\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "with open(working_dir+'/data/data_dump_single_atom_double_well_1000T_1x.pk', 'rb') as handle:\n",
    "    (input_list, all_data, training_indexes, testing_indexes) = pickle.load(handle)\n",
    "\n",
    "print(len(input_list))\n",
    "print(all_data.shape)\n",
    "print(len(training_indexes))\n",
    "print(len(testing_indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0RqleDWqKaGb",
    "outputId": "04da8c7b-3f60-4ead-b3f2-4848b490148b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 1000, 1)\n"
     ]
    }
   ],
   "source": [
    "all_data_selected = all_data[:,::10,1:2]\n",
    "print(all_data_selected.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EsLACAHoHMou"
   },
   "outputs": [],
   "source": [
    "scaler = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(all_data_selected.reshape(-1,1))\n",
    "#sc = preprocessing.MinMaxScaler() # s the probably the most famous scaling algorithm, and follows the following formula for each feature:\n",
    "#sc = preprocessing.StandardScaler() # assumes your data is normally distributed within each feature\n",
    "#sc = preprocessing.RobustScaler() # interquartile range, so if there are outliers in the data, you might want to consider the Robust Scaler\n",
    "#sc = preprocessing.Normalizer() # The normalizer scales each value by dividing each value by its magnitude in n-dimensional space for n number of features.\n",
    "#arr_transformed = sc.fit_transform(arr_selected)\n",
    "#scaled_data = scaled_data.reshape(-1,1000,1)\n",
    "scaled_data =all_data_selected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vIPlhIbG0wZt",
    "outputId": "64816060-01fe-4e82-8daa-ccacb918771e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=160000, minmax=(array([-3.1]), array([3.1])), mean=array([0.03887526]), variance=array([1.73019773]), skewness=array([-0.07182972]), kurtosis=array([-0.65559605]))"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy as sc\n",
    "sc.stats.describe(all_data_selected.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "hYxg8xOm7FMo",
    "outputId": "1fcc2d73-aeb3-4224-f179-62e741eb6652"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99500, 5)\n",
      "(99500,)\n"
     ]
    }
   ],
   "source": [
    "window_size=5\n",
    "input_data = []\n",
    "output = []\n",
    "for sim_ in training_indexes:\n",
    "#for sim_ in range(scaled_data.shape[0]):\n",
    "    for i in range(window_size, scaled_data.shape[1]):\n",
    "        input_data.append(scaled_data[sim_, (i-window_size):i, 0])\n",
    "        output.append(scaled_data[sim_, i, 0])\n",
    "\n",
    "input_data = np.array(input_data)\n",
    "output = np.array(output)\n",
    "print(input_data.shape)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "3UjpmpsT7FMr",
    "outputId": "e4c585fb-131a-4020-ccca-fc10182614c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  (99500, 5)\n",
      "Output (99500,)\n",
      "Train input:  (79600, 5, 1)\n",
      "Train Output (79600,)\n",
      "Test input:  (19900, 5, 1)\n",
      "Test Output (19900,)\n"
     ]
    }
   ],
   "source": [
    "input_data_suff, output_suff  = shuffle(input_data, output)\n",
    "\n",
    "train_test_split = 0.8\n",
    "train_test_split_ = int(input_data_suff.shape[0]*train_test_split)\n",
    "\n",
    "x_train = input_data_suff[0:train_test_split_].reshape(-1,window_size,1)\n",
    "x_test = input_data_suff[train_test_split_:].reshape(-1,window_size,1)\n",
    "y_train = output_suff[0:train_test_split_]\n",
    "y_test = output_suff[train_test_split_:]\n",
    "\n",
    "print(\"input: \", input_data_suff.shape)\n",
    "print(\"Output\", output_suff.shape)\n",
    "print(\"Train input: \", x_train.shape)\n",
    "print(\"Train Output\", y_train.shape)\n",
    "print(\"Test input: \", x_test.shape)\n",
    "print(\"Test Output\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rkZSPkaH7FMt"
   },
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "learningRate = 0.0005\n",
    "batchSize = 1024\n",
    "dropout_rate=0.2\n",
    "epochs=500\n",
    "\n",
    "input_shape = (window_size, 1)   #batchsize, timesteps, input_dim: this is a bad example here timesteps, input_dim are height and width\n",
    "\n",
    "# Network Parameters\n",
    "lstmUnits1 =32       # 1st layer number of neurons\n",
    "lstmUnits2 = 32       # 1st layer number of neurons\n",
    "output_shape = 1     # 435*7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is He initializer\n",
    "initializer = tf.keras.initializers.VarianceScaling(scale=2.0, mode='fan_in', distribution='truncated_normal', seed=None)\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.LSTM(lstmUnits1, activation=tf.nn.relu, kernel_initializer=initializer, input_shape=input_shape, return_sequences=True, recurrent_dropout=dropout_rate))\n",
    "model.add(tf.keras.layers.Dropout(rate=dropout_rate))\n",
    "model.add(tf.keras.layers.LSTM(lstmUnits2, activation=tf.nn.relu, kernel_initializer=initializer, recurrent_dropout=dropout_rate))\n",
    "model.add(tf.keras.layers.Dropout(rate=dropout_rate))\n",
    "#model.add(tf.keras.layers.Dense(32, activation=tf.nn.relu, kernel_initializer=initializer))\n",
    "model.add(tf.keras.layers.Dense(output_shape, activation=None, kernel_initializer=initializer))\n",
    "\n",
    "model.compile(loss=tf.keras.metrics.mean_squared_error,\n",
    "             optimizer=tf.keras.optimizers.Adam(lr=learningRate))\n",
    "\n",
    "#history = model.fit(x_train, y_train, epochs=epochs, batch_size = batchSize,verbose = 1, validation_data = (x_test, y_test))\n",
    "history = model.fit(x_train, y_train, epochs=epochs, batch_size = batchSize, verbose = 1, validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is 8 time frames\n",
    "#model.evaluate(x_test, y_test)\n",
    "# Save the model as a hdf5 file\n",
    "tf.keras.models.save_model(model=model,filepath=working_dir+'/one_particle_double_well_10X.HDF5')\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax.plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax)\n",
    "plt.yscale('log')\n",
    "legend = ax.legend(loc='best', shadow=True)\n",
    "\n",
    "#ax[1].plot(history.history['acc'], color='b', label=\"Training accuracy\")\n",
    "#ax[1].plot(history.history['val_acc'], color='r',label=\"Validation accuracy\")\n",
    "#legend = ax[1].legend(loc='best', shadow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "iU8uzmFd7FM1",
    "outputId": "d53b52db-6cb8-4f3b-b480-c1af56bd55be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 5, 32)             4352      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 5, 32)             0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 12,705\n",
      "Trainable params: 12,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_ =training_indexes[0]\n",
    "#sim_ =testing_indexes[18]\n",
    "\n",
    "actual_output = []\n",
    "predicted_output = []\n",
    "\n",
    "for i in range(window_size, 1000):\n",
    "  predicted_output.append(model.predict(scaled_data[sim_, (i-window_size):i, 0].reshape(-1, window_size, 1)))\n",
    "  actual_output.append(scaled_data[sim_, i, 0])\n",
    "\n",
    "actual_output = np.array(actual_output)\n",
    "predicted_output = np.array(predicted_output).reshape(-1)\n",
    "\n",
    "# This is to check continous RNN prediction\n",
    "Only_RNN_predicted_output = []\n",
    "\n",
    "temp__ = scaled_data[sim_, 0:window_size, 0]\n",
    "temp__ = np.append(temp__, predicted_output, axis=0)\n",
    "temp__.shape\n",
    "\n",
    "for i in range(window_size, 1000):\n",
    "  Only_RNN_predicted_output.append(model.predict(temp__[(i-window_size):i].reshape(-1, window_size, 1)))\n",
    "\n",
    "Only_RNN_predicted_output = np.array(Only_RNN_predicted_output).reshape(-1)\n",
    "\n",
    "\n",
    "print(actual_output.shape)\n",
    "print(predicted_output.shape)\n",
    "print(Only_RNN_predicted_output.shape)\n",
    "#print(predicted_output)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib notebook\n",
    "%matplotlib inline\n",
    "\n",
    "fig=plt.figure(figsize=(16, 6))\n",
    "plt.title(input_list[sim_])\n",
    "plt.plot(all_data_selected[sim_,window_size:,0],'r+', label='MD_dynamics', linewidth=1, markersize=3, linestyle='dashed')\n",
    "#plt.plot(scaler.inverse_transform(predicted_output.reshape(-1,1)), label='RNN predicted_dynamics')\n",
    "#plt.plot(scaler.inverse_transform(Only_RNN_predicted_output.reshape(-1,1)), label='continous RNN')\n",
    "plt.plot(predicted_output, label='RNN predicted_dynamics')\n",
    "plt.plot(Only_RNN_predicted_output, label='continous RNN')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "id": "RmJL7XVJ7FM4",
    "outputId": "2f32c5c9-6bd6-49d6-eeb5-b79d6bfb285c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# Load the keras model\n",
    "model = tf.keras.models.load_model(filepath=working_dir+'/one_particle_double_well_10X.HDF5', compile=True)\n",
    "#y_pred = model.predict(x_test)\n",
    "#y_pred_classes = model.predict_classes(x_test)\n",
    "#cm = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "#print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "wLPNmhOXTAU2",
    "outputId": "2076cac8-b892-4c7d-8e1d-1363df07025e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "(2, 10000, 6)\n",
      "1\n",
      "1\n",
      "(2, 1000, 1)\n"
     ]
    }
   ],
   "source": [
    "with open(working_dir+'/data/doble_well_critical_1x.pk', 'rb') as handle:\n",
    "    (input_list_critical, all_data_critical, training_indexes_critical, testing_indexes_critical) = pickle.load(handle)\n",
    "\n",
    "print(len(input_list_critical))\n",
    "print(all_data_critical.shape)\n",
    "print(len(training_indexes_critical))\n",
    "print(len(testing_indexes_critical))\n",
    "\n",
    "all_data_critical_selected = all_data_critical[:,::10,1:2]\n",
    "print(all_data_critical_selected.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sim_ =training_indexes[3]\n",
    "sim_ =testing_indexes[5]\n",
    "\n",
    "actual_output = []\n",
    "predicted_output = []\n",
    "\n",
    "for i in range(window_size, 1000):\n",
    "  predicted_output.append(model.predict(scaled_data[sim_, (i-window_size):i, 0].reshape(-1, window_size, 1)))\n",
    "  actual_output.append(scaled_data[sim_, i, 0])\n",
    "\n",
    "actual_output = np.array(actual_output)\n",
    "predicted_output = np.array(predicted_output).reshape(-1)\n",
    "\n",
    "# This is to check continous RNN prediction\n",
    "Only_RNN_predicted_output = []\n",
    "\n",
    "temp__ = scaled_data[sim_, 0:window_size, 0]\n",
    "temp__ = np.append(temp__, predicted_output, axis=0)\n",
    "temp__.shape\n",
    "\n",
    "for i in range(window_size, 1000):\n",
    "  Only_RNN_predicted_output.append(model.predict(temp__[(i-window_size):i].reshape(-1, window_size, 1)))\n",
    "\n",
    "Only_RNN_predicted_output = np.array(Only_RNN_predicted_output).reshape(-1)\n",
    "\n",
    "\n",
    "print(actual_output.shape)\n",
    "print(predicted_output.shape)\n",
    "print(Only_RNN_predicted_output.shape)\n",
    "#print(predicted_output)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib notebook\n",
    "%matplotlib inline\n",
    "\n",
    "fig=plt.figure(figsize=(16, 6))\n",
    "plt.title(input_list[sim_])\n",
    "plt.plot(all_data_selected[sim_,window_size:,0],'r+', label='MD_dynamics', linewidth=1, markersize=3, linestyle='dashed')\n",
    "#plt.plot(scaler.inverse_transform(predicted_output.reshape(-1,1)), label='RNN predicted_dynamics')\n",
    "#plt.plot(scaler.inverse_transform(Only_RNN_predicted_output.reshape(-1,1)), label='continous RNN')\n",
    "plt.plot(predicted_output, label='RNN predicted_dynamics')\n",
    "plt.plot(Only_RNN_predicted_output, label='continous RNN')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_ =0\n",
    "\n",
    "actual_output = []\n",
    "predicted_output = []\n",
    "\n",
    "how_many_steps=200\n",
    "\n",
    "for i in range(window_size, how_many_steps):\n",
    "  predicted_output.append(model.predict(all_data_critical_selected[sim_, (i-window_size):i, 0].reshape(-1, window_size, 1)))\n",
    "  actual_output.append(all_data_critical_selected[sim_, i, 0])\n",
    "\n",
    "actual_output = np.array(actual_output)\n",
    "predicted_output = np.array(predicted_output).reshape(-1)\n",
    "\n",
    "# This is to check continous RNN prediction\n",
    "Only_RNN_predicted_output = []\n",
    "\n",
    "temp__ = all_data_critical_selected[sim_, 0:window_size, 0]\n",
    "temp__ = np.append(temp__, predicted_output, axis=0)\n",
    "temp__.shape\n",
    "\n",
    "for i in range(window_size, how_many_steps):\n",
    "  Only_RNN_predicted_output.append(model.predict(temp__[(i-window_size):i].reshape(-1, window_size, 1)))\n",
    "\n",
    "Only_RNN_predicted_output = np.array(Only_RNN_predicted_output).reshape(-1)\n",
    "\n",
    "\n",
    "print(actual_output.shape)\n",
    "print(predicted_output.shape)\n",
    "print(Only_RNN_predicted_output.shape)\n",
    "#print(predicted_output)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib notebook\n",
    "%matplotlib inline\n",
    "\n",
    "fig=plt.figure(figsize=(16, 6))\n",
    "plt.title(input_list_critical[sim_])\n",
    "plt.plot(actual_output,'r+', label='MD_dynamics', linewidth=1, markersize=3, linestyle='dashed')\n",
    "#plt.plot(scaler.inverse_transform(predicted_output.reshape(-1,1)), label='RNN predicted_dynamics')\n",
    "#plt.plot(scaler.inverse_transform(Only_RNN_predicted_output.reshape(-1,1)), label='continous RNN')\n",
    "plt.plot(predicted_output, label='RNN predicted_dynamics')\n",
    "plt.plot(Only_RNN_predicted_output, label='continous RNN')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_ =1\n",
    "\n",
    "actual_output = []\n",
    "predicted_output = []\n",
    "\n",
    "how_many_steps=200\n",
    "\n",
    "for i in range(window_size, how_many_steps):\n",
    "  predicted_output.append(model.predict(all_data_critical_selected[sim_, (i-window_size):i, 0].reshape(-1, window_size, 1)))\n",
    "  actual_output.append(all_data_critical_selected[sim_, i, 0])\n",
    "\n",
    "actual_output = np.array(actual_output)\n",
    "predicted_output = np.array(predicted_output).reshape(-1)\n",
    "\n",
    "# This is to check continous RNN prediction\n",
    "Only_RNN_predicted_output = []\n",
    "\n",
    "temp__ = all_data_critical_selected[sim_, 0:window_size, 0]\n",
    "temp__ = np.append(temp__, predicted_output, axis=0)\n",
    "temp__.shape\n",
    "\n",
    "for i in range(window_size, how_many_steps):\n",
    "  Only_RNN_predicted_output.append(model.predict(temp__[(i-window_size):i].reshape(-1, window_size, 1)))\n",
    "\n",
    "Only_RNN_predicted_output = np.array(Only_RNN_predicted_output).reshape(-1)\n",
    "\n",
    "\n",
    "print(actual_output.shape)\n",
    "print(predicted_output.shape)\n",
    "print(Only_RNN_predicted_output.shape)\n",
    "#print(predicted_output)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib notebook\n",
    "%matplotlib inline\n",
    "\n",
    "fig=plt.figure(figsize=(16, 6))\n",
    "plt.title(input_list_critical[sim_])\n",
    "plt.plot(actual_output,'r+', label='MD_dynamics', linewidth=1, markersize=3, linestyle='dashed')\n",
    "#plt.plot(scaler.inverse_transform(predicted_output.reshape(-1,1)), label='RNN predicted_dynamics')\n",
    "#plt.plot(scaler.inverse_transform(Only_RNN_predicted_output.reshape(-1,1)), label='continous RNN')\n",
    "plt.plot(predicted_output, label='RNN predicted_dynamics')\n",
    "plt.plot(Only_RNN_predicted_output, label='continous RNN')\n",
    "plt.legend()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "one_particle_double_well.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
