{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "colab_type": "code",
    "id": "6rArcV417GhV",
    "outputId": "d45d90a0-3f5a-45ad-abca-c8508154dc12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount._DEBUG = False\n",
    "drive.mount('/content/gdrive/')\n",
    "#!ls /content/gdrive/'My Drive'/Deeplearning/RA_Work/NEMD_Simulations/all_data/data_dump.pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "S2UbX98A7Zo-",
    "outputId": "e6868d2c-bc73-42ad-a06b-eede3b3dcbd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data  Lyapunov-data  one_particle_lj_10X.HDF5  one_particle_lj.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls /content/gdrive/'My Drive'/Deeplearning/RA_Work/one_particle_LJ\n",
    "working_dir = '/content/gdrive/My Drive/Deeplearning/RA_Work/one_particle_LJ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 82
    },
    "colab_type": "code",
    "id": "XHw0ZGUl7FMd",
    "outputId": "b232b7a4-f6ba-4e30-8a07-453ffb1da3b1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1.15.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lib imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as PathEffects\n",
    "%matplotlib inline\n",
    "plt.style.use('default')\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_palette('muted')\n",
    "sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sys, os, io, string, shutil, math\n",
    "import glob\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import FastICA \n",
    "from sklearn import preprocessing\n",
    "from IPython.display import display\n",
    "import scipy.linalg as la\n",
    "import re\n",
    "from tabulate import tabulate\n",
    "from scipy import stats\n",
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "import random\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "a-sXwUhLAOeP",
    "outputId": "de168d91-1e62-44ad-8d58-47f9117f1814"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110\n",
      "(110, 9999, 6)\n",
      "50\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "with open(working_dir+'/data/data_dump_single_atom_LJ_100T_1x.pk', 'rb') as handle:\n",
    "    (input_list, all_data, training_indexes, testing_indexes) = pickle.load(handle)\n",
    "\n",
    "print(len(input_list))\n",
    "print(all_data.shape)\n",
    "print(len(training_indexes))\n",
    "print(len(testing_indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "0RqleDWqKaGb",
    "outputId": "fe4d917e-1df4-40f1-a699-88c20fb44bca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(110, 1000, 1)\n"
     ]
    }
   ],
   "source": [
    "all_data_selected = all_data[:,::10,1:2]\n",
    "print(all_data_selected.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vIPlhIbG0wZt"
   },
   "outputs": [],
   "source": [
    "import scipy as sc\n",
    "sc.stats.describe(all_data_selected.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "#scaled_data = scaler.fit_transform(all_data_selected.reshape(-1,1))\n",
    "#sc = preprocessing.MinMaxScaler() # s the probably the most famous scaling algorithm, and follows the following formula for each feature:\n",
    "#sc = preprocessing.StandardScaler() # assumes your data is normally distributed within each feature\n",
    "#sc = preprocessing.RobustScaler() # interquartile range, so if there are outliers in the data, you might want to consider the Robust Scaler\n",
    "#sc = preprocessing.Normalizer() # The normalizer scales each value by dividing each value by its magnitude in n-dimensional space for n number of features.\n",
    "#arr_transformed = sc.fit_transform(arr_selected)\n",
    "#scaled_data = scaled_data.reshape(-1,1000,1)\n",
    "scaled_data =all_data_selected\n",
    "scaled_data = all_data_critical_selected.reshape(-1,1000,1)\n",
    "print(scaled_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "hYxg8xOm7FMo",
    "outputId": "18d6de1b-7240-4dce-ce83-a4cf80cc82cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(995, 5)\n",
      "(995,)\n"
     ]
    }
   ],
   "source": [
    "window_size=5\n",
    "input_data = []\n",
    "output = []\n",
    "#for sim_ in training_indexes[0:20]:\n",
    "for sim_ in  range(0, 1):\n",
    "#for sim_ in range(scaled_data.shape[0]):\n",
    "    for i in range(window_size, scaled_data.shape[1]):\n",
    "        input_data.append(scaled_data[sim_, (i-window_size):i, 0])\n",
    "        output.append(scaled_data[sim_, i, 0])\n",
    "\n",
    "input_data = np.array(input_data)\n",
    "output = np.array(output)\n",
    "print(input_data.shape)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "3UjpmpsT7FMr",
    "outputId": "14ecb94d-414e-497b-dc9d-de5c82fd0bce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  (995, 5)\n",
      "Output (995,)\n",
      "Train input:  (945, 5, 1)\n",
      "Train Output (945,)\n",
      "Test input:  (50, 5, 1)\n",
      "Test Output (50,)\n"
     ]
    }
   ],
   "source": [
    "input_data_suff, output_suff  = shuffle(input_data, output)\n",
    "\n",
    "train_test_split = 0.95\n",
    "train_test_split_ = int(input_data_suff.shape[0]*train_test_split)\n",
    "\n",
    "x_train = input_data_suff[0:train_test_split_].reshape(-1,window_size,1)\n",
    "x_test = input_data_suff[train_test_split_:].reshape(-1,window_size,1)\n",
    "y_train = output_suff[0:train_test_split_]\n",
    "y_test = output_suff[train_test_split_:]\n",
    "\n",
    "print(\"input: \", input_data_suff.shape)\n",
    "print(\"Output\", output_suff.shape)\n",
    "print(\"Train input: \", x_train.shape)\n",
    "print(\"Train Output\", y_train.shape)\n",
    "print(\"Test input: \", x_test.shape)\n",
    "print(\"Test Output\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rkZSPkaH7FMt"
   },
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "learningRate = 0.001\n",
    "batchSize = 32\n",
    "dropout_rate=0.1\n",
    "epochs=1\n",
    "\n",
    "input_shape = (window_size, 1)   #batchsize, timesteps, input_dim: this is a bad example here timesteps, input_dim are height and width\n",
    "\n",
    "# Network Parameters\n",
    "lstmUnits1 =128       # 1st layer number of neurons\n",
    "lstmUnits2 = 128       # 1st layer number of neurons\n",
    "output_shape = 1     # 435*7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "PCW2i1na7FMw",
    "outputId": "dc7adf5d-87fd-4d22-92cd-a947783d48be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 945 samples, validate on 50 samples\n",
      "945/945 [==============================] - 3s 3ms/sample - loss: 1.9958 - val_loss: 0.3918\n"
     ]
    }
   ],
   "source": [
    "#This is He initializer\n",
    "initializer = tf.keras.initializers.VarianceScaling(scale=2.0, mode='fan_in', distribution='truncated_normal', seed=None)\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.LSTM(lstmUnits1, activation=tf.nn.tanh, kernel_initializer=initializer, input_shape=input_shape, return_sequences=True, recurrent_dropout=dropout_rate))\n",
    "model.add(tf.keras.layers.Dropout(rate=dropout_rate))\n",
    "model.add(tf.keras.layers.LSTM(lstmUnits2, activation=tf.nn.tanh, kernel_initializer=initializer, recurrent_dropout=dropout_rate))\n",
    "model.add(tf.keras.layers.Dropout(rate=dropout_rate))\n",
    "#model.add(tf.keras.layers.Dense(32, activation=tf.nn.relu, kernel_initializer=initializer))\n",
    "model.add(tf.keras.layers.Dense(output_shape, activation=None, kernel_initializer=initializer))\n",
    "\n",
    "model.compile(loss=tf.keras.metrics.mean_squared_error,\n",
    "             optimizer=tf.keras.optimizers.Adam(lr=learningRate))\n",
    "\n",
    "#history = model.fit(x_train, y_train, epochs=epochs, batch_size = batchSize,verbose = 1, validation_data = (x_test, y_test))\n",
    "history = model.fit(x_train, y_train, epochs=epochs, batch_size = batchSize, verbose = 1, validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is 8 time frames\n",
    "#model.evaluate(x_test, y_test)\n",
    "# Save the model as a hdf5 file\n",
    "tf.keras.models.save_model(model=model,filepath=working_dir+'/one_particle_lj_10X.HDF5')\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax.plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax)\n",
    "plt.yscale('log')\n",
    "legend = ax.legend(loc='best', shadow=True)\n",
    "\n",
    "#ax[1].plot(history.history['acc'], color='b', label=\"Training accuracy\")\n",
    "#ax[1].plot(history.history['val_acc'], color='r',label=\"Validation accuracy\")\n",
    "#legend = ax[1].legend(loc='best', shadow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 341
    },
    "colab_type": "code",
    "id": "iU8uzmFd7FM1",
    "outputId": "ed35117a-260a-4b95-9c37-7e0609169233"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_8 (LSTM)                (None, 5, 128)            66560     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 5, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 198,273\n",
      "Trainable params: 198,273\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "id": "RmJL7XVJ7FM4",
    "outputId": "e1969119-6119-4a0b-fb48-1d58e175bfd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# Load the keras model\n",
    "model = tf.keras.models.load_model(filepath=working_dir+'/one_particle_lj_10X.HDF5', compile=True)\n",
    "#y_pred = model.predict(x_test)\n",
    "#y_pred_classes = model.predict_classes(x_test)\n",
    "#cm = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "#print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_ =training_indexes[28]\n",
    "#sim_ =testing_indexes[5]\n",
    "#sim_ = 3\n",
    "how_many_steps=100\n",
    "actual_output = []\n",
    "predicted_output = []\n",
    "\n",
    "for i in range(window_size, how_many_steps):\n",
    "  predicted_output.append(model.predict(scaled_data[sim_, (i-window_size):i, 0].reshape(-1, window_size, 1)))\n",
    "  actual_output.append(scaled_data[sim_, i, 0])\n",
    "\n",
    "actual_output = np.array(actual_output)\n",
    "predicted_output = np.array(predicted_output).reshape(-1)\n",
    "\n",
    "# This is to check continous RNN prediction\n",
    "Only_RNN_predicted_output = []\n",
    "\n",
    "temp__ = scaled_data[sim_, 0:window_size, 0]\n",
    "temp__ = np.append(temp__, predicted_output, axis=0)\n",
    "temp__.shape\n",
    "\n",
    "for i in range(window_size, how_many_steps):\n",
    "  Only_RNN_predicted_output.append(model.predict(temp__[(i-window_size):i].reshape(-1, window_size, 1)))\n",
    "\n",
    "Only_RNN_predicted_output = np.array(Only_RNN_predicted_output).reshape(-1)\n",
    "\n",
    "\n",
    "print(actual_output.shape)\n",
    "print(predicted_output.shape)\n",
    "print(Only_RNN_predicted_output.shape)\n",
    "#print(predicted_output)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib notebook\n",
    "%matplotlib inline\n",
    "\n",
    "fig=plt.figure(figsize=(16, 6))\n",
    "plt.title(input_list[sim_])\n",
    "plt.plot(scaled_data[sim_,0:how_many_steps],'r+', label='MD_dynamics', linewidth=1, markersize=3, linestyle='dashed')\n",
    "#plt.plot(scaler.inverse_transform(predicted_output.reshape(-1,1)), label='RNN predicted_dynamics')\n",
    "#plt.plot(scaler.inverse_transform(Only_RNN_predicted_output.reshape(-1,1)), label='continous RNN')\n",
    "#plt.plot(predicted_output, label='RNN predicted_dynamics')\n",
    "plt.plot(temp__, label='continous RNN')\n",
    "plt.legend()\n",
    "\n",
    "#print(temp__[0:5])\n",
    "#print(scaled_data[sim_,0:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sim_ =training_indexes[3]\n",
    "sim_ =testing_indexes[5]\n",
    "\n",
    "actual_output = []\n",
    "predicted_output = []\n",
    "\n",
    "for i in range(window_size, 1000):\n",
    "  predicted_output.append(model.predict(scaled_data[sim_, (i-window_size):i, 0].reshape(-1, window_size, 1)))\n",
    "  actual_output.append(scaled_data[sim_, i, 0])\n",
    "\n",
    "actual_output = np.array(actual_output)\n",
    "predicted_output = np.array(predicted_output).reshape(-1)\n",
    "\n",
    "# This is to check continous RNN prediction\n",
    "Only_RNN_predicted_output = []\n",
    "\n",
    "temp__ = scaled_data[sim_, 0:window_size, 0]\n",
    "temp__ = np.append(temp__, predicted_output, axis=0)\n",
    "temp__.shape\n",
    "\n",
    "for i in range(window_size, 1000):\n",
    "  Only_RNN_predicted_output.append(model.predict(temp__[(i-window_size):i].reshape(-1, window_size, 1)))\n",
    "\n",
    "Only_RNN_predicted_output = np.array(Only_RNN_predicted_output).reshape(-1)\n",
    "\n",
    "\n",
    "print(actual_output.shape)\n",
    "print(predicted_output.shape)\n",
    "print(Only_RNN_predicted_output.shape)\n",
    "#print(predicted_output)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib notebook\n",
    "%matplotlib inline\n",
    "\n",
    "fig=plt.figure(figsize=(16, 6))\n",
    "plt.title(input_list[sim_])\n",
    "plt.plot(all_data_selected[sim_,window_size:,0],'r+', label='MD_dynamics', linewidth=1, markersize=3, linestyle='dashed')\n",
    "plt.plot(scaler.inverse_transform(predicted_output.reshape(-1,1)), label='RNN predicted_dynamics')\n",
    "plt.plot(scaler.inverse_transform(Only_RNN_predicted_output.reshape(-1,1)), label='continous RNN')\n",
    "\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_ =0\n",
    "\n",
    "actual_output = []\n",
    "predicted_output = []\n",
    "time_data = []\n",
    "how_many_steps=1000\n",
    "\n",
    "for i in range(window_size, how_many_steps):\n",
    "  predicted_output.append(model.predict(all_data_critical_selected[(i-window_size):i, 0].reshape(-1, window_size, 1)))\n",
    "  actual_output.append(all_data_critical_selected[i, 0])\n",
    "  time_data.append(all_data_critical_selected_time[i, 0])\n",
    "\n",
    "actual_output = np.array(actual_output)\n",
    "predicted_output = np.array(predicted_output).reshape(-1)\n",
    "time_data = np.array(time_data)\n",
    "\n",
    "# This is to check continous RNN prediction\n",
    "Only_RNN_predicted_output = []\n",
    "\n",
    "temp__ = all_data_critical_selected[0:window_size, 0]\n",
    "temp__ = np.append(temp__, predicted_output, axis=0)\n",
    "temp__.shape\n",
    "\n",
    "for i in range(window_size, how_many_steps):\n",
    "  Only_RNN_predicted_output.append(model.predict(temp__[(i-window_size):i].reshape(-1, window_size, 1)))\n",
    "\n",
    "Only_RNN_predicted_output = np.array(Only_RNN_predicted_output).reshape(-1)\n",
    "\n",
    "\n",
    "print(actual_output.shape)\n",
    "print(predicted_output.shape)\n",
    "print(Only_RNN_predicted_output.shape)\n",
    "#print(predicted_output)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib notebook\n",
    "%matplotlib inline\n",
    "\n",
    "fig=plt.figure(figsize=(16, 6))\n",
    "#plt.title(input_list_critical[sim_])\n",
    "plt.plot( time_data, actual_output,'r+', label='MD_dynamics', linewidth=1, markersize=3, linestyle='dashed')\n",
    "#plt.plot(scaler.inverse_transform(predicted_output.reshape(-1,1)), label='RNN predicted_dynamics')\n",
    "#plt.plot(scaler.inverse_transform(Only_RNN_predicted_output.reshape(-1,1)), label='continous RNN')\n",
    "#plt.plot(predicted_output, label='RNN predicted_dynamics')\n",
    "plt.plot(time_data, Only_RNN_predicted_output, label='continous RNN')\n",
    "plt.legend()\n",
    "\n",
    "np.savetxt(working_dir+'/Lyapunov-data/RNN-shift_vo=0.010000.out', np.column_stack((time_data, actual_output, Only_RNN_predicted_output)), delimiter='\\t')\n",
    "    \n",
    "fig=plt.figure(figsize=(16, 6))\n",
    "#plt.title(\"Error plot: \" + input_list_critical[sim_])\n",
    "plt.plot((actual_output-Only_RNN_predicted_output)**2, label='Sqaured_Pos_error')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "e28mCY9n9eYP",
    "outputId": "d9bd14d5-710b-42c4-a244-4c9625c5f481"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1)\n"
     ]
    }
   ],
   "source": [
    "#Lyapunov-data\n",
    "\n",
    "#simulated_result_file = np.loadtxt(working_dir+'/Lyapunov-data/correct.out')\n",
    "simulated_result_file = np.loadtxt(working_dir+'/Lyapunov-data/shift_vo=0.010000.out')\n",
    "\n",
    "\n",
    "all_data_critical_selected = simulated_result_file[::10,1:2]\n",
    "all_data_critical_selected_time = simulated_result_file[::10,0:1]\n",
    "print(all_data_critical_selected.shape)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "one_particle_lj.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
